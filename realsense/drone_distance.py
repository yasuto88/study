"""
drone_distance.py
-----------------
YOLOv5 ã§ãƒ‰ãƒ­ãƒ¼ãƒ³ã‚’æ¤œçŸ¥ã—ã€RealSense D435/D435i ã®æ·±åº¦æƒ…å ±ã‚’ä½¿ã£ã¦
è·é›¢ï¼ˆmmï¼‰ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºã—ã¾ã™ã€‚

æ“ä½œ:
  ESC â€¦ çµ‚äº†
  S   â€¦ ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜ï¼ˆcaptures/ ä»¥ä¸‹ï¼‰
"""

from pathlib import Path
import os

import cv2
import numpy as np
import pyrealsense2 as rs
import torch

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ¦ãƒ¼ã‚¶è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_PATH = "drone_yolov5nu.pt"  # å­¦ç¿’æ¸ˆã¿ã‚¦ã‚§ã‚¤ãƒˆ
CONF_THRES = 0.30  # æ¤œå‡ºä¿¡é ¼åº¦ã—ãã„å€¤
BOX_COLOR = (0, 255, 0)  # BGR
LABEL_COLOR = (0, 255, 255)
DEPTH_AVG_KERNEL = 7  # kÃ—k ã®ä¸­å¤®å€¤ (å¥‡æ•°)
DEVICE = "cpu"  # CUDA ä½¿ç”¨ãªã‚‰ "cuda:0"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# RealSense åˆæœŸåŒ–
cfg = rs.config()
cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)

pipe = rs.pipeline()
align = rs.align(rs.stream.color)
prof = pipe.start(cfg)
depth_scale = prof.get_device().first_depth_sensor().get_depth_scale()

# YOLOv5 ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
print("ğŸ”„ Loading YOLOv5 model â€¦")
model = torch.hub.load(
    "ultralytics/yolov5",
    "custom",
    path=MODEL_PATH,
    device=DEVICE,
    trust_repo=True,  # GitHub ä¸Šã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä¿¡é ¼
)
model.conf = CONF_THRES  # æ—¢å®šé–¾å€¤ã‚’è¨­å®š
print("âœ… Model loaded")


# æ·±åº¦å–å¾—ãƒ˜ãƒ«ãƒ‘
def depth_at_bbox(depth_img: np.ndarray, cx: int, cy: int, k: int = DEPTH_AVG_KERNEL):
    """BBox ä¸­å¤® kÃ—k ãƒ‘ãƒƒãƒã®æ·±åº¦ä¸­å¤®å€¤ [m] ã‚’è¿”ã™ï¼ˆinvalid=0 ã¯é™¤å¤–ï¼‰"""
    h, w = depth_img.shape
    k2 = k // 2
    x1, x2 = max(cx - k2, 0), min(cx + k2 + 1, w)
    y1, y2 = max(cy - k2, 0), min(cy + k2 + 1, h)
    patch = depth_img[y1:y2, x1:x2]
    patch = patch[patch > 0]
    return float(np.median(patch)) * depth_scale if patch.size else None


# ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
print("â–¶ ESC = quit,  S = save frame")
save_dir = Path("captures")
save_dir.mkdir(exist_ok=True)
save_idx = 0

try:
    while True:
        frames = align.process(pipe.wait_for_frames())
        depth_img = np.asanyarray(frames.get_depth_frame().get_data())
        color_img = np.asanyarray(frames.get_color_frame().get_data())

        # æ¨è«– (BGRâ†’RGB ã¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§è‡ªå‹•å¤‰æ›)
        results = model(color_img, size=640)

        # 1æšç›®ã®æ¨è«–çµæœã‚’å‡¦ç†
        for *xyxy, conf, cls in results.xyxy[0]:
            if int(cls) != 0:  # 0 = "drone" ã‚’æƒ³å®š
                continue

            x1, y1, x2, y2 = map(int, xyxy)
            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2

            dist_m = depth_at_bbox(depth_img, cx, cy)
            if dist_m is None:
                continue

            cv2.rectangle(color_img, (x1, y1), (x2, y2), BOX_COLOR, 2)
            cv2.circle(color_img, (cx, cy), 4, BOX_COLOR, -1)
            cv2.putText(
                color_img,
                f"{dist_m*1000:.0f} mm",
                (x1, y1 - 8),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                LABEL_COLOR,
                2,
            )

        cv2.imshow("Drone distance", color_img)
        key = cv2.waitKey(1) & 0xFF
        if key == 27:  # ESC
            break
        elif key in (ord("s"), ord("S")):
            cv2.imwrite(str(save_dir / f"frame_{save_idx:03d}.png"), color_img)
            print(f"ğŸ’¾ Saved captures/frame_{save_idx:03d}.png")
            save_idx += 1

finally:
    pipe.stop()
    cv2.destroyAllWindows()
